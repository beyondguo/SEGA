{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hai hai hai, huggingface sega lai la!\n",
    "from transformers import pipeline\n",
    "\n",
    "sega = pipeline(\"text2text-generation\",model='beyond/sega-large', device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Conference on Empirical Methods welcomes the submission of research papers. Abstracts should be in the form of a paper or presentation. Please submit abstracts to the following email address: eemml.stanford.edu. The conference will be held at Stanford University on April 1618, 2019. The theme of the conference is Deep Learning.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketch = \"<mask> Conference on Empirical Methods <mask> submission of research papers <mask> Deep Learning <mask>\"\n",
    "generated_text = sega(sketch, num_beams=3, do_sample=True, max_length=200)[0]['generated_text']\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# model_path = 'saved_models/bart-large-c4-l_50_200-d_13799838-yake_mask-t_3900800/checkpoint-91425'\n",
    "model_path = 'saved_models/bart-large-c4-l_50_200-d_13799838-yake_mask-t_3900800/checkpoint-152375'\n",
    "sega = pipeline(\"text2text-generation\",model=model_path, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Bad news: the European Union will not be able to increase the price of corn until next month by EU's Farm Commissioner Franz means. That's according to a report from Reuters. The report says the EU will have to raise the price by 1.5 percent next year. Corn prices have been rising steadily for the past few years, and are now at their highest level since 2007.\"}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sega('Bad news: <mask> the European Union <mask> month by EU <mask> Farm Commissioner Franz <mask>', num_beams=3, do_sample=True, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business: <mask> Mickle Jordan <mask> in China <mask>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'business: \"Mickle Jordan has done a great job for us in China. He\\'s been very helpful to us. We look forward to working with him in the future. I think he\\'s going to be a great asset to us in the near future.\"'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kws = ['Mickle Jordan', 'in China']\n",
    "sketch = 'business: ' + '<mask> '+' <mask> '.join(kws)+' <mask>'\n",
    "print(sketch)\n",
    "sega(sketch, num_beams=3, do_sample=True, max_length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"There's nothing compelling here. There are no real cats. There's no prophecies of Armageddon. It's just the story of an Australian couple who are trying to make it as a family in a small town in the middle of nowhere.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sega(\"<mask> nothing compelling <mask> no real cats <mask> prophecies of Armageddon <mask> of an Australian <mask>\", max_length=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sega_gen(kws,n):\n",
    "    M = ' <mask> '\n",
    "    t = M.join(kws)\n",
    "    res = sega(t, num_beams=3, do_sample=True, num_return_sequences=n, max_length=100)\n",
    "    res = [each['generated_text'] for each in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what a nice day! I have a plan for the sun beach. I like to drink and food, surfing, swimming, etc. I would like to go on a bike ride and have a good time. I want to go to the beach with my friends and family.',\n",
       " 'what a nice day! I have a plan for the sun beach, drink and food, surfing, swimming, etc. I am looking forward to it! I am also looking for a place for my friends and family to go for a swim. I want to have fun and enjoy it.',\n",
       " 'what a nice day. I have a plan. sun beach with a drink and food. surfing, swimming and more. I am looking forward to the day.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kws = ['what a nice day', 'I have a plan', 'sun beach', 'drink and food', 'surfing', 'swimming']\n",
    "sega_gen(kws, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like machine learning. I like to join a conference, doing research, and learning about natural language processing. I have a passion for machine learning, but I am also interested in learning about the future of AI.',\n",
       " 'I like machine learning, so when I join a conference, I think about doing research on natural language processing. I like the idea of using AI to solve problems. I think that it makes a lot of sense to do research on things like this.',\n",
       " 'I like machine learning. I would like to join a conference where I would be doing research on natural language processing. I also like to learn how to use AI to improve the performance of computers.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kws = ['I like machine learning', 'join a conference', 'doing research', 'natural language processing']\n",
    "sega_gen(kws, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chess world No. 1 Magnus Carlsen outright has been accused by Hans Niemann of cheating.',\n",
       " 'Chess world No. 1 Magnus Carlsen outright is accused by Hans Niemann of cheating..',\n",
       " 'Chess world No. 1 Magnus Carlsen outright has been accused by Hans Niemann of cheating.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kws = ['Chess world <mask> Magnus Carlsen outright <mask> Hans Niemann of cheating.']\n",
    "sega_gen(kws, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "class K2T_Generator:\n",
    "    def __init__(self,model, device):\n",
    "        self.generator = pipeline(\"text2text-generation\", model=model, device=device)\n",
    "    def k2t(self, inputs, beam=1, sample=False, max_length=200):\n",
    "        \"\"\"\n",
    "        inputs: text or a list of text\n",
    "        \"\"\"\n",
    "        res = self.generator(inputs, num_beams=beam, do_sample=sample, num_return_sequences=1, max_length=max_length)\n",
    "        return [item['generated_text'] for item in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10000 documents for pre-training\n",
    "model = f'saved_models/bart-large-c4-l_50_200-d_1000000-yake_mask-t_281571/checkpoint-6600'\n",
    "# model = f'facebook/bart-large'\n",
    "generator = K2T_Generator(model, device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.k2t('what the fuck is going hell on?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "ss = ['nice weekend movie fun',\n",
    "      'Shanghai food water help citizens virus',\n",
    "      'England ship China ocean Paris cake people',\n",
    "      'joint great food great drinks greater staff',\n",
    "      'Wuhan hot-dry noodel delicious breakfirst China street Hubuxiang tour nice place',]*2\n",
    "for s in ss:\n",
    "    s = s.replace(' ',' <mask> ')\n",
    "    s = '<mask> '+s+' <mask>'\n",
    "    print(generator.k2t(s))\n",
    "print(time.time()-t,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ss):\n",
    "        self.ss = ss\n",
    "        self.ss = ['<mask> '+s.replace(' ',' <mask> ')+' <mask>' for s in ss]\n",
    "    def __len__(self):\n",
    "        return len(self.ss)\n",
    "    def __getitem__(self, i):\n",
    "        return self.ss[i]\n",
    "data = MyDataset(ss)\n",
    "data.__getitem__(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "for out in generator.generator(data,num_beams=5, do_sample=True, num_return_sequences=1, max_length=200,batch_size=10):\n",
    "    print(out)\n",
    "print(time.time()-t,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_name = 'imdb_50'\n",
    "data = pd.read_csv(f'clf_data/{dataset_name}/train.csv')\n",
    "data = data.dropna()\n",
    "data = data[data.content != ''] # 处理空值问题\n",
    "contents = list(data.content)\n",
    "labels = list(data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 抽出最大为3的ngram\n",
    "\n",
    "def mask_unimportant_parts(text, max_ngram=3, topk=20):\n",
    "    ke_yake = yake.KeywordExtractor(n=max_ngram,top=topk)\n",
    "    kws_paris = ke_yake.extract_keywords(text) \n",
    "    kws =  [pair[0] for pair in kws_paris]\n",
    "\n",
    "    words_idxs = []\n",
    "    all_ids = []\n",
    "    for w in kws: # 找出每个词的位置\n",
    "        for m in list(re.finditer(w,text)): \n",
    "            all_ids += list(range(m.start(),m.end()))\n",
    "    all_ids = sorted(list(set(all_ids)))\n",
    "    # 给不连续的部分中间补上mask token\n",
    "    masked_text = []\n",
    "    for i,id in enumerate(all_ids):\n",
    "        if i == 0 and id != 0: # 开头补mask\n",
    "            masked_text.append('<mask> ')\n",
    "        if id - all_ids[i-1] > 1: # 说明中间有东西\n",
    "            masked_text.append(' <mask> ')\n",
    "        masked_text.append(text[id])\n",
    "        if i == len(all_ids)-1 and id != len(text)-1: # 最后补mask\n",
    "            masked_text.append(' <mask>')\n",
    "    masked_text = ''.join(masked_text)\n",
    "    return masked_text\n",
    "\n",
    "mask_unimportant_parts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show(i):\n",
    "    print(labels[i], contents[i])\n",
    "for i in range(10):\n",
    "    print('>>>',i)\n",
    "    show(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mask_unimportant_parts(contents[4],topk=20)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "elements = m.split('<mask>')\n",
    "shuffle_elements = random.shuffle(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.k2t(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('conda': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}